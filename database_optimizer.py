#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®åº“æ€§èƒ½ä¼˜åŒ–æ¨¡å—

ä¼˜åŒ–æ–¹æ¡ˆ:
1. åˆ†è¡¨å­˜å‚¨ - æŒ‰æ—¥æœŸ/å¸‚åœºåˆ†è¡¨
2. ç´¢å¼•ä¼˜åŒ– - å¤šçº§ç´¢å¼•åŠ é€ŸæŸ¥è¯¢
3. åˆ†åŒºå­˜å‚¨ - å†·çƒ­æ•°æ®åˆ†ç¦»
4. æ‰¹é‡æ“ä½œ - å‡å°‘äº‹åŠ¡æ¬¡æ•°
5. è¿æ¥æ±  - å¤ç”¨è¿æ¥

ç›®æ ‡ï¼š
- 50000+åªè‚¡ç¥¨ Ã— 1000æ¡æ•°æ® = 5000ä¸‡æ¡è®°å½•
- æŸ¥è¯¢å“åº”æ—¶é—´ < 100ms
- å†™å…¥ååé‡ > 10000æ¡/ç§’

Author: ä»™å„¿ä»™å„¿ç¢ç¢å¿µ
"""

import sqlite3
from datetime import datetime, timedelta
from pathlib import Path
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class DatabaseOptimizer:
    """æ•°æ®åº“ä¼˜åŒ–å™¨"""
    
    def __init__(self, db_path='logs/quotes.db'):
        self.db_path = db_path
    
    def create_optimized_schema(self):
        """åˆ›å»ºä¼˜åŒ–çš„æ•°æ®åº“ç»“æ„"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # 1. ä¸»è¡¨ - åˆ†è¡¨å­˜å‚¨
        # æŒ‰æ—¥æœŸåˆ†è¡¨: minute_bars_20260120, minute_bars_20260121, ...
        
        # åˆ›å»ºåŸºç¡€è¡¨ï¼ˆæœ€æ–°æ•°æ®ï¼‰
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS minute_bars (
                id INTEGER PRIMARY KEY,
                symbol TEXT NOT NULL,
                minute TEXT NOT NULL,
                open REAL NOT NULL,
                high REAL NOT NULL,
                low REAL NOT NULL,
                close REAL NOT NULL,
                volume INTEGER NOT NULL,
                amount INTEGER,
                created_at TEXT DEFAULT CURRENT_TIMESTAMP,
                UNIQUE(symbol, minute)
            )
        """)
        
        # 2. ä¼˜åŒ–çš„ç´¢å¼•
        cursor.executescript("""
            CREATE INDEX IF NOT EXISTS idx_symbol_time 
            ON minute_bars(symbol, minute DESC);
            
            CREATE INDEX IF NOT EXISTS idx_time 
            ON minute_bars(minute DESC);
            
            CREATE INDEX IF NOT EXISTS idx_symbol 
            ON minute_bars(symbol);
            
            CREATE INDEX IF NOT EXISTS idx_close 
            ON minute_bars(close);
        """)
        
        # 3. åˆ†å‹è¡¨ï¼ˆå­˜å‚¨å·²è¯†åˆ«çš„åˆ†å‹ï¼‰
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS fractals (
                id INTEGER PRIMARY KEY,
                symbol TEXT NOT NULL,
                minute TEXT NOT NULL,
                fractal_type TEXT NOT NULL,  -- 'top' or 'bottom'
                high REAL,
                low REAL,
                close REAL,
                strength REAL,  -- åˆ†å‹å¼ºåº¦ 0-1
                created_at TEXT DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        cursor.execute("""
            CREATE INDEX IF NOT EXISTS idx_fractals_symbol_time 
            ON fractals(symbol, minute DESC)
        """)
        
        # 4. ä¿¡å·è¡¨ï¼ˆå­˜å‚¨äº¤æ˜“ä¿¡å·ï¼‰
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS signals (
                id INTEGER PRIMARY KEY,
                symbol TEXT NOT NULL,
                signal_time TEXT NOT NULL,
                signal_type TEXT NOT NULL,  -- 'buy' or 'sell'
                price REAL NOT NULL,
                confidence REAL,  -- ä¿¡å¿ƒåº¦ 0-1
                reason TEXT,
                status TEXT DEFAULT 'pending',  -- pending/active/closed
                created_at TEXT DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        cursor.execute("""
            CREATE INDEX IF NOT EXISTS idx_signals_symbol_status 
            ON signals(symbol, status)
        """)
        
        # 5. ç»Ÿè®¡è¡¨ï¼ˆç¼“å­˜ç»Ÿè®¡æ•°æ®ï¼‰
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS statistics (
                id INTEGER PRIMARY KEY,
                symbol TEXT NOT NULL,
                date TEXT NOT NULL,
                fractal_count INTEGER,
                signal_count INTEGER,
                high REAL,
                low REAL,
                close REAL,
                volume INTEGER,
                updated_at TEXT DEFAULT CURRENT_TIMESTAMP,
                UNIQUE(symbol, date)
            )
        """)
        
        # 6. å¥åº·æ£€æŸ¥è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS health_check (
                id INTEGER PRIMARY KEY,
                check_time TEXT NOT NULL,
                total_symbols INTEGER,
                total_records INTEGER,
                last_update TEXT,
                status TEXT,
                notes TEXT
            )
        """)
        
        conn.commit()
        conn.close()
        
        logger.info("âœ“ ä¼˜åŒ–çš„æ•°æ®åº“ç»“æ„å·²åˆ›å»º")
    
    def enable_optimizations(self):
        """å¯ç”¨æ•°æ®åº“ä¼˜åŒ–"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # å¯ç”¨äº‹åŠ¡æ”¯æŒ
        cursor.execute("PRAGMA journal_mode = WAL")  # é¢„å†™æ—¥å¿—æ¨¡å¼
        
        # å¢åŠ ç¼“å­˜
        cursor.execute("PRAGMA cache_size = -64000")  # 64MB
        
        # å…³é”®è·¯å¾„æ¨¡å¼
        cursor.execute("PRAGMA query_only = OFF")
        cursor.execute("PRAGMA synchronous = NORMAL")  # ç‰ºç‰²ä¸€ç‚¹å®‰å…¨æ€§æ¢æ€§èƒ½
        
        # ä¸´æ—¶è¡¨ä½¿ç”¨å†…å­˜
        cursor.execute("PRAGMA temp_store = MEMORY")
        
        conn.commit()
        conn.close()
        
        logger.info("âœ“ æ•°æ®åº“ä¼˜åŒ–å‚æ•°å·²åº”ç”¨")
    
    def analyze_tables(self):
        """åˆ†æè¡¨ç»Ÿè®¡ï¼ˆæå‡æŸ¥è¯¢ä¼˜åŒ–ï¼‰"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("ANALYZE")
        
        conn.commit()
        conn.close()
        
        logger.info("âœ“ è¡¨ç»Ÿè®¡åˆ†æå®Œæˆ")
    
    def batch_insert(self, table: str, records: list, batch_size=1000):
        """
        æ‰¹é‡æ’å…¥æ•°æ®
        
        Args:
            table: è¡¨å
            records: è®°å½•åˆ—è¡¨ [{col: value, ...}, ...]
            batch_size: æ‰¹é‡å¤§å°
        """
        if not records:
            return
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # è·å–åˆ—å
        columns = list(records[0].keys())
        placeholders = ','.join(['?' for _ in columns])
        
        insert_sql = f"INSERT OR REPLACE INTO {table} ({','.join(columns)}) VALUES ({placeholders})"
        
        # åˆ†æ‰¹æ’å…¥
        for i in range(0, len(records), batch_size):
            batch = records[i:i+batch_size]
            values = [tuple(r.get(col) for col in columns) for r in batch]
            
            cursor.executemany(insert_sql, values)
            conn.commit()
            
            if i % 5000 == 0:
                logger.info(f"âœ“ å·²æ’å…¥{i+len(batch)}/{len(records)}æ¡è®°å½•")
        
        conn.close()
    
    def vacuum_database(self):
        """æ¸…ç†å’Œä¼˜åŒ–æ•°æ®åº“"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("VACUUM")  # é‡æ–°æ•´ç†æ•°æ®åº“
        
        conn.commit()
        conn.close()
        
        logger.info("âœ“ æ•°æ®åº“æ¸…ç†å®Œæˆ")
    
    def get_health_status(self):
        """è·å–æ•°æ®åº“å¥åº·çŠ¶æ€"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # ç»Ÿè®¡æ•°æ®
        cursor.execute("SELECT COUNT(DISTINCT symbol), COUNT(*) FROM minute_bars")
        symbols, records = cursor.fetchone()
        
        cursor.execute("SELECT MAX(minute) FROM minute_bars")
        last_update = cursor.fetchone()[0]
        
        cursor.execute("SELECT SIZE FROM (SELECT SUM(pgsize) AS SIZE FROM dbstat)")
        try:
            db_size = cursor.fetchone()[0]
        except:
            db_size = Path(self.db_path).stat().st_size if Path(self.db_path).exists() else 0
        
        conn.close()
        
        health = {
            'timestamp': datetime.now().isoformat(),
            'symbols_count': symbols,
            'total_records': records,
            'avg_records_per_symbol': records // max(symbols, 1) if symbols > 0 else 0,
            'last_update': last_update,
            'db_size_mb': db_size / (1024 * 1024) if db_size else 0,
            'status': 'HEALTHY' if symbols > 0 and records > 0 else 'UNHEALTHY',
        }
        
        return health
    
    def optimize_all(self):
        """æ‰§è¡Œå®Œæ•´ä¼˜åŒ–"""
        logger.info("å¼€å§‹æ•°æ®åº“ä¼˜åŒ–...")
        
        self.create_optimized_schema()
        self.enable_optimizations()
        self.analyze_tables()
        self.vacuum_database()
        
        health = self.get_health_status()
        
        print("\n" + "="*70)
        print("ğŸ“Š æ•°æ®åº“å¥åº·çŠ¶æ€")
        print("="*70)
        for key, value in health.items():
            if isinstance(value, float):
                print(f"  {key:.<40} {value:.2f}")
            else:
                print(f"  {key:.<40} {value}")
        print("="*70 + "\n")
        
        return health


class ConnectionPool:
    """æ•°æ®åº“è¿æ¥æ± """
    
    def __init__(self, db_path='logs/quotes.db', pool_size=5):
        self.db_path = db_path
        self.pool_size = pool_size
        self.connections = []
        self._init_pool()
    
    def _init_pool(self):
        """åˆå§‹åŒ–è¿æ¥æ± """
        for _ in range(self.pool_size):
            conn = sqlite3.connect(self.db_path, check_same_thread=False)
            self.connections.append(conn)
    
    def get_connection(self):
        """è·å–è¿æ¥"""
        if self.connections:
            return self.connections.pop()
        return sqlite3.connect(self.db_path, check_same_thread=False)
    
    def return_connection(self, conn):
        """å½’è¿˜è¿æ¥"""
        if len(self.connections) < self.pool_size:
            self.connections.append(conn)
        else:
            conn.close()
    
    def close_all(self):
        """å…³é—­æ‰€æœ‰è¿æ¥"""
        for conn in self.connections:
            conn.close()
        self.connections.clear()


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='æ•°æ®åº“ä¼˜åŒ–å·¥å…·')
    parser.add_argument('--db', default='logs/quotes.db', help='æ•°æ®åº“è·¯å¾„')
    parser.add_argument('--optimize', action='store_true', help='æ‰§è¡Œä¼˜åŒ–')
    parser.add_argument('--health', action='store_true', help='æ£€æŸ¥å¥åº·çŠ¶æ€')
    parser.add_argument('--vacuum', action='store_true', help='æ•°æ®åº“æ¸…ç†')
    
    args = parser.parse_args()
    
    optimizer = DatabaseOptimizer(args.db)
    
    if args.optimize:
        optimizer.optimize_all()
    elif args.health:
        health = optimizer.get_health_status()
        print("\næ•°æ®åº“å¥åº·æŠ¥å‘Š:")
        print(json.dumps(health, indent=2, ensure_ascii=False))
    elif args.vacuum:
        optimizer.vacuum_database()
    else:
        optimizer.create_optimized_schema()
        optimizer.enable_optimizations()


if __name__ == '__main__':
    import json
    main()
