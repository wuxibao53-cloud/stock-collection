#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
5000+ A è‚¡é‡‡é›†éªŒè¯å·¥å…·
ç”¨äºéªŒè¯å…¨ A è‚¡é‡‡é›†æ˜¯å¦æ­£å¸¸å·¥ä½œ

ä½¿ç”¨æ–¹å¼ï¼š
    python verify_collection.py --mode hot --db logs/quotes.db
    python verify_collection.py --mode full --db logs/quotes.db --check-quality
    python verify_collection.py --generate-report --db logs/quotes.db --output report.md
"""

import sqlite3
import argparse
import json
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Any
from collections import defaultdict


class CollectionVerifier:
    """é‡‡é›†éªŒè¯å·¥å…·"""
    
    def __init__(self, db_path: str):
        self.db_path = db_path
        self.conn = sqlite3.connect(db_path)
        self.cursor = self.conn.cursor()
    
    def __enter__(self):
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.conn.close()
    
    # ==================== æ•°æ®ç»Ÿè®¡ ====================
    
    def get_summary_stats(self) -> Dict[str, Any]:
        """è·å–é‡‡é›†æ‘˜è¦ç»Ÿè®¡"""
        
        stats = {}
        
        # æ€»ä½“ç»Ÿè®¡
        self.cursor.execute('SELECT COUNT(DISTINCT symbol), COUNT(*), COUNT(DISTINCT minute) FROM minute_bars')
        symbols, records, dates = self.cursor.fetchone()
        
        stats['total_symbols'] = symbols
        stats['total_records'] = records
        stats['total_dates'] = dates
        stats['avg_records_per_symbol'] = records // max(symbols, 1)
        
        # æ•°æ®è·¨åº¦
        self.cursor.execute('SELECT MIN(minute), MAX(minute) FROM minute_bars')
        min_date, max_date = self.cursor.fetchone()
        stats['date_range'] = f"{min_date} to {max_date}"
        
        # æ•°æ®è´¨é‡
        self.cursor.execute('''
            SELECT 
                COUNT(CASE WHEN open IS NOT NULL THEN 1 END) as open_count,
                COUNT(CASE WHEN close IS NOT NULL THEN 1 END) as close_count,
                COUNT(CASE WHEN volume > 0 THEN 1 END) as volume_count
            FROM minute_bars
        ''')
        open_cnt, close_cnt, vol_cnt = self.cursor.fetchone()
        
        stats['data_quality'] = {
            'open_present_pct': (open_cnt / max(records, 1) * 100),
            'close_present_pct': (close_cnt / max(records, 1) * 100),
            'volume_present_pct': (vol_cnt / max(records, 1) * 100)
        }
        
        return stats
    
    def get_symbol_distribution(self) -> Dict[str, Any]:
        """è·å–è‚¡ç¥¨åˆ†å¸ƒç»Ÿè®¡"""
        
        self.cursor.execute('''
            SELECT 
                symbol,
                COUNT(*) as record_count,
                MIN(minute) as first_date,
                MAX(minute) as last_date,
                AVG(close) as avg_price,
                MAX(close) as max_price,
                MIN(close) as min_price
            FROM minute_bars
            GROUP BY symbol
            ORDER BY record_count DESC
        ''')
        
        distribution = []
        for row in self.cursor.fetchall():
            symbol, cnt, first, last, avg_price, max_p, min_p = row
            distribution.append({
                'symbol': symbol,
                'records': cnt,
                'first_date': first,
                'last_date': last,
                'avg_price': round(avg_price, 2) if avg_price else None,
                'price_range': (round(min_p, 2), round(max_p, 2)) if (min_p and max_p) else None
            })
        
        return {
            'top_10_symbols': distribution[:10],
            'total_symbols': len(distribution),
            'bottom_10_symbols': distribution[-10:] if len(distribution) > 10 else []
        }
    
    def get_market_segment_stats(self) -> Dict[str, Any]:
        """è·å–å¸‚åœºåˆ†æ®µç»Ÿè®¡ï¼ˆä¸Šè¯/æ·±è¯/åˆ›ä¸šæ¿/åŒ—äº¤æ‰€ï¼‰"""
        
        segments = {}
        
        # å®šä¹‰å¸‚åœºå‰ç¼€
        market_prefixes = {
            'ä¸Šè¯': 'sh',
            'æ·±è¯': 'sz',
            'åˆ›ä¸šæ¿': 'sz3',
            'ç§‘åˆ›æ¿': 'sh6',
            'åŒ—äº¤æ‰€': 'bj'
        }
        
        for market, prefix in market_prefixes.items():
            self.cursor.execute(f'''
                SELECT 
                    COUNT(DISTINCT symbol) as count,
                    COUNT(*) as records,
                    AVG(close) as avg_price
                FROM minute_bars
                WHERE symbol LIKE '{prefix}%'
            ''')
            
            count, records, avg_price = self.cursor.fetchone()
            if count > 0:
                segments[market] = {
                    'stock_count': count,
                    'record_count': records,
                    'avg_price': round(avg_price, 2) if avg_price else 0
                }
        
        return segments
    
    def check_data_quality(self) -> Dict[str, Any]:
        """æ£€æŸ¥æ•°æ®è´¨é‡é—®é¢˜"""
        
        issues = {
            'missing_prices': 0,
            'missing_volumes': 0,
            'invalid_prices': 0,
            'duplicate_records': 0,
            'data_gaps': []
        }
        
        # 1. ç¼ºå¤±çš„ä»·æ ¼
        self.cursor.execute('SELECT COUNT(*) FROM minute_bars WHERE close IS NULL OR open IS NULL')
        issues['missing_prices'] = self.cursor.fetchone()[0]
        
        # 2. ç¼ºå¤±çš„æˆäº¤é‡
        self.cursor.execute('SELECT COUNT(*) FROM minute_bars WHERE volume IS NULL OR volume = 0')
        issues['missing_volumes'] = self.cursor.fetchone()[0]
        
        # 3. å¼‚å¸¸ä»·æ ¼ï¼ˆæç«¯é«˜ä½ï¼‰
        self.cursor.execute('''
            SELECT COUNT(*) FROM minute_bars 
            WHERE close > 10000 OR close < 0.01
        ''')
        issues['invalid_prices'] = self.cursor.fetchone()[0]
        
        # 4. é‡å¤è®°å½•
        self.cursor.execute('''
            SELECT COUNT(*) FROM (
                SELECT symbol, minute, COUNT(*) as cnt
                FROM minute_bars
                GROUP BY symbol, minute
                HAVING cnt > 1
            )
        ''')
        issues['duplicate_records'] = self.cursor.fetchone()[0]
        
        # 5. æ•°æ®é—´éš™æ£€æŸ¥
        self.cursor.execute('''
            SELECT DISTINCT symbol FROM minute_bars
            WHERE symbol LIKE 'sh%' OR symbol LIKE 'sz%'
            LIMIT 10
        ''')
        
        sample_symbols = [row[0] for row in self.cursor.fetchall()]
        for symbol in sample_symbols[:5]:
            self.cursor.execute(f'''
                SELECT COUNT(DISTINCT DATE(minute)) 
                FROM minute_bars 
                WHERE symbol = '{symbol}'
            ''')
            date_count = self.cursor.fetchone()[0]
            
            self.cursor.execute(f'''
                SELECT MIN(DATE(minute)), MAX(DATE(minute))
                FROM minute_bars
                WHERE symbol = '{symbol}'
            ''')
            min_date, max_date = self.cursor.fetchone()
            
            if min_date and max_date:
                delta = (datetime.fromisoformat(max_date) - datetime.fromisoformat(min_date)).days + 1
                gap = delta - date_count
                if gap > 5:
                    issues['data_gaps'].append({
                        'symbol': symbol,
                        'expected_days': delta,
                        'actual_days': date_count,
                        'gap_days': gap
                    })
        
        return issues
    
    def get_performance_metrics(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½æŒ‡æ ‡"""
        
        # æŸ¥è¯¢é€Ÿåº¦æµ‹è¯•
        import time
        
        metrics = {}
        
        # æµ‹è¯•èŒƒå›´æŸ¥è¯¢
        start = time.time()
        self.cursor.execute('SELECT COUNT(*) FROM minute_bars WHERE close > 10 AND close < 100')
        self.cursor.fetchone()
        metrics['range_query_time'] = (time.time() - start) * 1000  # æ¯«ç§’
        
        # æµ‹è¯•åˆ†ç»„æŸ¥è¯¢
        start = time.time()
        self.cursor.execute('SELECT symbol, COUNT(*) FROM minute_bars GROUP BY symbol')
        self.cursor.fetchall()
        metrics['groupby_query_time'] = (time.time() - start) * 1000
        
        # æµ‹è¯•æ’åºæŸ¥è¯¢
        start = time.time()
        self.cursor.execute('SELECT * FROM minute_bars ORDER BY close DESC LIMIT 100')
        self.cursor.fetchall()
        metrics['sort_query_time'] = (time.time() - start) * 1000
        
        # æ•°æ®åº“æ–‡ä»¶å¤§å°
        import os
        file_size = os.path.getsize(self.db_path) / (1024 * 1024)  # MB
        metrics['db_file_size_mb'] = round(file_size, 2)
        
        return metrics
    
    # ==================== æŠ¥å‘Šç”Ÿæˆ ====================
    
    def generate_html_report(self, output_path: str = None) -> str:
        """ç”Ÿæˆ HTML æ ¼å¼çš„è¯¦ç»†æŠ¥å‘Š"""
        
        stats = self.get_summary_stats()
        dist = self.get_symbol_distribution()
        segments = self.get_market_segment_stats()
        quality = self.check_data_quality()
        perf = self.get_performance_metrics()
        
        html = f"""
<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>ç¼ è®ºç³»ç»Ÿ - Aè‚¡é‡‡é›†éªŒè¯æŠ¥å‘Š</title>
    <style>
        body {{ font-family: Arial, sans-serif; margin: 20px; background: #f5f5f5; }}
        .container {{ max-width: 1200px; margin: 0 auto; background: white; padding: 20px; border-radius: 8px; }}
        h1 {{ color: #333; border-bottom: 3px solid #07C160; padding-bottom: 10px; }}
        h2 {{ color: #666; margin-top: 30px; }}
        .metric {{ 
            display: inline-block; 
            background: #f0f9ff; 
            padding: 15px; 
            margin: 10px; 
            border-radius: 5px; 
            border-left: 4px solid #07C160;
        }}
        .metric-value {{ font-size: 24px; font-weight: bold; color: #07C160; }}
        .metric-label {{ font-size: 12px; color: #999; }}
        table {{ width: 100%; border-collapse: collapse; margin: 20px 0; }}
        th {{ background: #07C160; color: white; padding: 10px; text-align: left; }}
        td {{ padding: 10px; border-bottom: 1px solid #ddd; }}
        tr:hover {{ background: #f9f9f9; }}
        .status-ok {{ color: #07C160; font-weight: bold; }}
        .status-warning {{ color: #FFA500; font-weight: bold; }}
        .status-error {{ color: #FF3B30; font-weight: bold; }}
        .timestamp {{ color: #999; font-size: 12px; text-align: right; }}
    </style>
</head>
<body>
    <div class="container">
        <h1>âœ… ç¼ è®ºäº¤æ˜“ç³»ç»Ÿ - å…¨Aè‚¡é‡‡é›†éªŒè¯æŠ¥å‘Š</h1>
        <p class="timestamp">ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
        
        <h2>ğŸ“Š é‡‡é›†æ‘˜è¦</h2>
        <div>
            <div class="metric">
                <div class="metric-value">{stats['total_symbols']:,}</div>
                <div class="metric-label">é‡‡é›†è‚¡ç¥¨æ•°</div>
            </div>
            <div class="metric">
                <div class="metric-value">{stats['total_records']:,}</div>
                <div class="metric-label">æ•°æ®è®°å½•æ•°</div>
            </div>
            <div class="metric">
                <div class="metric-value">{stats['avg_records_per_symbol']:.0f}</div>
                <div class="metric-label">å¹³å‡æ¯è‚¡è®°å½•</div>
            </div>
            <div class="metric">
                <div class="metric-value">{stats['total_dates']}</div>
                <div class="metric-label">äº¤æ˜“æ—¥æœŸæ•°</div>
            </div>
        </div>
        
        <h2>ğŸ™ï¸ å¸‚åœºåˆ†å¸ƒ</h2>
        <table>
            <tr>
                <th>å¸‚åœº</th>
                <th>è‚¡ç¥¨æ•°</th>
                <th>æ•°æ®æ¡æ•°</th>
                <th>å¹³å‡ä»·æ ¼</th>
            </tr>
            {"".join(f"<tr><td>{k}</td><td>{v['stock_count']}</td><td>{v['record_count']}</td><td>Â¥{v['avg_price']}</td></tr>" for k, v in segments.items())}
        </table>
        
        <h2>â­ çƒ­é—¨è‚¡ç¥¨ TOP 10</h2>
        <table>
            <tr>
                <th>ä»£ç </th>
                <th>æ•°æ®æ¡æ•°</th>
                <th>æœ€ä½ä»·</th>
                <th>å¹³å‡ä»·</th>
                <th>æœ€é«˜ä»·</th>
                <th>æ•°æ®å‘¨æœŸ</th>
            </tr>
            {"".join(f'''<tr>
                <td>{s['symbol']}</td>
                <td>{s['records']}</td>
                <td>Â¥{s['price_range'][0]}</td>
                <td>Â¥{s['avg_price']}</td>
                <td>Â¥{s['price_range'][1]}</td>
                <td>{s['first_date']} ~ {s['last_date']}</td>
            </tr>''' for s in dist['top_10_symbols'])}
        </table>
        
        <h2>ğŸ” æ•°æ®è´¨é‡æ£€æŸ¥</h2>
        <table>
            <tr>
                <th>æ£€æŸ¥é¡¹</th>
                <th>ç»“æœ</th>
                <th>çŠ¶æ€</th>
            </tr>
            <tr>
                <td>ç¼ºå¤±ä»·æ ¼è®°å½•</td>
                <td>{quality['missing_prices']} æ¡</td>
                <td class="{'status-ok' if quality['missing_prices'] < 100 else 'status-warning'}">{'âœ“ OK' if quality['missing_prices'] < 100 else 'âš  éœ€è¦å…³æ³¨'}</td>
            </tr>
            <tr>
                <td>ç¼ºå¤±æˆäº¤é‡</td>
                <td>{quality['missing_volumes']} æ¡</td>
                <td class="{'status-ok' if quality['missing_volumes'] < 100 else 'status-warning'}">{'âœ“ OK' if quality['missing_volumes'] < 100 else 'âš  éœ€è¦å…³æ³¨'}</td>
            </tr>
            <tr>
                <td>å¼‚å¸¸ä»·æ ¼</td>
                <td>{quality['invalid_prices']} æ¡</td>
                <td class="{'status-ok' if quality['invalid_prices'] == 0 else 'status-error'}">{'âœ“ OK' if quality['invalid_prices'] == 0 else 'âŒ æœ‰é—®é¢˜'}</td>
            </tr>
            <tr>
                <td>é‡å¤è®°å½•</td>
                <td>{quality['duplicate_records']} æ¡</td>
                <td class="{'status-ok' if quality['duplicate_records'] == 0 else 'status-error'}">{'âœ“ OK' if quality['duplicate_records'] == 0 else 'âŒ æœ‰é—®é¢˜'}</td>
            </tr>
        </table>
        
        <h2>âš¡ æ€§èƒ½æŒ‡æ ‡</h2>
        <table>
            <tr>
                <th>æŒ‡æ ‡</th>
                <th>æ•°å€¼</th>
            </tr>
            <tr>
                <td>æ•°æ®åº“æ–‡ä»¶å¤§å°</td>
                <td>{perf['db_file_size_mb']} MB</td>
            </tr>
            <tr>
                <td>èŒƒå›´æŸ¥è¯¢è€—æ—¶</td>
                <td>{perf['range_query_time']:.1f} ms</td>
            </tr>
            <tr>
                <td>åˆ†ç»„æŸ¥è¯¢è€—æ—¶</td>
                <td>{perf['groupby_query_time']:.1f} ms</td>
            </tr>
            <tr>
                <td>æ’åºæŸ¥è¯¢è€—æ—¶</td>
                <td>{perf['sort_query_time']:.1f} ms</td>
            </tr>
        </table>
        
        <h2>âœ… éªŒè¯ç»“æœ</h2>
        <table>
            <tr>
                <th>éªŒè¯é¡¹</th>
                <th>ç»“æœ</th>
            </tr>
            <tr>
                <td>è‚¡ç¥¨è¦†ç›– (5000+ ç›®æ ‡)</td>
                <td class="{'status-ok' if stats['total_symbols'] >= 5000 else 'status-warning'}">{stats['total_symbols']:,} {'âœ“ PASS' if stats['total_symbols'] >= 5000 else 'âš  éœ€è¦è¡¥å……'}</td>
            </tr>
            <tr>
                <td>æ•°æ®é‡å……è¶³ (50000+ ç›®æ ‡)</td>
                <td class="{'status-ok' if stats['total_records'] >= 50000 else 'status-warning'}">{stats['total_records']:,} {'âœ“ PASS' if stats['total_records'] >= 50000 else 'âš  éœ€è¦è¡¥å……'}</td>
            </tr>
            <tr>
                <td>æ•°æ®è´¨é‡ (> 99%)</td>
                <td class="{'status-ok' if stats['data_quality']['close_present_pct'] > 99 else 'status-warning'}">{stats['data_quality']['close_present_pct']:.1f}% {'âœ“ PASS' if stats['data_quality']['close_present_pct'] > 99 else 'âš  éœ€è¦æ”¹è¿›'}</td>
            </tr>
        </table>
        
        <p style="margin-top: 40px; color: #999; text-align: center;">
            æœ¬æŠ¥å‘Šç”±ç¼ è®ºäº¤æ˜“ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒã€‚
        </p>
    </div>
</body>
</html>
"""
        
        if output_path:
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(html)
            print(f"âœ“ HTML æŠ¥å‘Šå·²ä¿å­˜: {output_path}")
        
        return html
    
    def generate_markdown_report(self, output_path: str = None) -> str:
        """ç”Ÿæˆ Markdown æ ¼å¼çš„æŠ¥å‘Š"""
        
        stats = self.get_summary_stats()
        dist = self.get_symbol_distribution()
        segments = self.get_market_segment_stats()
        quality = self.check_data_quality()
        perf = self.get_performance_metrics()
        
        md = f"""# ç¼ è®ºäº¤æ˜“ç³»ç»Ÿ - å…¨Aè‚¡é‡‡é›†éªŒè¯æŠ¥å‘Š

**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

---

## ğŸ“Š é‡‡é›†æ‘˜è¦

| æŒ‡æ ‡ | æ•°å€¼ |
|------|------|
| é‡‡é›†è‚¡ç¥¨æ•° | {stats['total_symbols']:,} åª |
| é‡‡é›†æ•°æ®æ¡æ•° | {stats['total_records']:,} æ¡ |
| å¹³å‡æ¯è‚¡æ•°æ® | {stats['avg_records_per_symbol']:.0f} æ¡ |
| äº¤æ˜“æ—¥æœŸæ•° | {stats['total_dates']} å¤© |
| æ•°æ®æ—¶é—´èŒƒå›´ | {stats['date_range']} |

---

## ğŸ™ï¸ å¸‚åœºåˆ†å¸ƒ

### å„å¸‚åœºè‚¡ç¥¨ç»Ÿè®¡

| å¸‚åœº | è‚¡ç¥¨æ•° | æ•°æ®æ¡æ•° | å¹³å‡ä»·æ ¼ |
|------|--------|---------|----------|
{chr(10).join(f"| {k} | {v['stock_count']} | {v['record_count']} | Â¥{v['avg_price']} |" for k, v in segments.items())}

---

## â­ çƒ­é—¨è‚¡ç¥¨ TOP 10

| ä»£ç  | æ•°æ®æ¡æ•° | æœ€ä½ä»· | å¹³å‡ä»· | æœ€é«˜ä»· | æ•°æ®å‘¨æœŸ |
|------|---------|--------|--------|--------|---------|
{chr(10).join(f"| {s['symbol']} | {s['records']} | Â¥{s['price_range'][0]} | Â¥{s['avg_price']} | Â¥{s['price_range'][1]} | {s['first_date']} ~ {s['last_date']} |" for s in dist['top_10_symbols'])}

---

## ğŸ” æ•°æ®è´¨é‡æ£€æŸ¥

| æ£€æŸ¥é¡¹ | æ•°å€¼ | çŠ¶æ€ |
|--------|------|------|
| ç¼ºå¤±ä»·æ ¼ | {quality['missing_prices']} æ¡ | {'âœ“ OK' if quality['missing_prices'] < 100 else 'âš  éœ€è¦å…³æ³¨'} |
| ç¼ºå¤±æˆäº¤é‡ | {quality['missing_volumes']} æ¡ | {'âœ“ OK' if quality['missing_volumes'] < 100 else 'âš  éœ€è¦å…³æ³¨'} |
| å¼‚å¸¸ä»·æ ¼ | {quality['invalid_prices']} æ¡ | {'âœ“ OK' if quality['invalid_prices'] == 0 else 'âŒ æœ‰é—®é¢˜'} |
| é‡å¤è®°å½• | {quality['duplicate_records']} æ¡ | {'âœ“ OK' if quality['duplicate_records'] == 0 else 'âŒ æœ‰é—®é¢˜'} |

---

## âš¡ æ€§èƒ½æŒ‡æ ‡

| æŒ‡æ ‡ | æ•°å€¼ |
|------|------|
| æ•°æ®åº“æ–‡ä»¶å¤§å° | {perf['db_file_size_mb']} MB |
| èŒƒå›´æŸ¥è¯¢ | {perf['range_query_time']:.1f} ms |
| åˆ†ç»„æŸ¥è¯¢ | {perf['groupby_query_time']:.1f} ms |
| æ’åºæŸ¥è¯¢ | {perf['sort_query_time']:.1f} ms |

---

## âœ… éªŒè¯ç»“æœ

| éªŒè¯é¡¹ | ç›®æ ‡ | å®é™… | çŠ¶æ€ |
|--------|------|------|------|
| è‚¡ç¥¨è¦†ç›– | 5000+ | {stats['total_symbols']:,} | {'âœ“ PASS' if stats['total_symbols'] >= 5000 else 'âš  FAIL'} |
| æ•°æ®é‡ | 50000+ | {stats['total_records']:,} | {'âœ“ PASS' if stats['total_records'] >= 50000 else 'âš  FAIL'} |
| æ•°æ®è´¨é‡ | >99% | {stats['data_quality']['close_present_pct']:.1f}% | {'âœ“ PASS' if stats['data_quality']['close_present_pct'] > 99 else 'âš  FAIL'} |

---

## ğŸ¯ å»ºè®®

"""
        
        recommendations = []
        if stats['total_symbols'] < 5000:
            recommendations.append("- âš ï¸ è‚¡ç¥¨è¦†ç›–ä¸è¶³ï¼Œå»ºè®®ç»§ç»­é‡‡é›†")
        if stats['total_records'] < 50000:
            recommendations.append("- âš ï¸ æ•°æ®é‡ä¸è¶³ï¼Œå»ºè®®é‡‡é›†æ›´å¤šå†å²æ•°æ®")
        if quality['invalid_prices'] > 0:
            recommendations.append("- âŒ å‘ç°å¼‚å¸¸ä»·æ ¼æ•°æ®ï¼Œå»ºè®®è¿›è¡Œæ•°æ®æ¸…æ´—")
        if quality['duplicate_records'] > 0:
            recommendations.append("- âŒ å‘ç°é‡å¤è®°å½•ï¼Œå»ºè®®è¿›è¡Œå»é‡å¤„ç†")
        if not recommendations:
            recommendations.append("- âœ… æ‰€æœ‰æ£€æŸ¥éƒ½é€šè¿‡ï¼Œç³»ç»Ÿè¿è¡Œæ­£å¸¸")
        
        md += "\n".join(recommendations)
        
        if output_path:
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(md)
            print(f"âœ“ Markdown æŠ¥å‘Šå·²ä¿å­˜: {output_path}")
        
        return md
    
    def print_summary(self):
        """æ‰“å°æ‘˜è¦ä¿¡æ¯"""
        
        stats = self.get_summary_stats()
        segments = self.get_market_segment_stats()
        quality = self.check_data_quality()
        
        print("\n" + "="*60)
        print("ğŸ“Š ç¼ è®ºäº¤æ˜“ç³»ç»Ÿ - é‡‡é›†éªŒè¯æ‘˜è¦")
        print("="*60 + "\n")
        
        # åŸºæœ¬ç»Ÿè®¡
        print("ğŸ“ˆ åŸºæœ¬ç»Ÿè®¡:")
        print(f"  â€¢ é‡‡é›†è‚¡ç¥¨æ•°: {stats['total_symbols']:,} åª")
        print(f"  â€¢ é‡‡é›†æ•°æ®æ¡æ•°: {stats['total_records']:,} æ¡")
        print(f"  â€¢ å¹³å‡æ¯è‚¡: {stats['avg_records_per_symbol']:.0f} æ¡")
        print(f"  â€¢ æ•°æ®è·¨åº¦: {stats['date_range']}\n")
        
        # å¸‚åœºåˆ†å¸ƒ
        print("ğŸ™ï¸ å¸‚åœºåˆ†å¸ƒ:")
        for market, data in segments.items():
            print(f"  â€¢ {market}: {data['stock_count']} åªè‚¡ç¥¨, {data['record_count']} æ¡æ•°æ®")
        print()
        
        # æ•°æ®è´¨é‡
        print("ğŸ” æ•°æ®è´¨é‡:")
        print(f"  â€¢ ç¼ºå¤±ä»·æ ¼: {quality['missing_prices']} æ¡")
        print(f"  â€¢ ç¼ºå¤±æˆäº¤é‡: {quality['missing_volumes']} æ¡")
        print(f"  â€¢ å¼‚å¸¸ä»·æ ¼: {quality['invalid_prices']} æ¡")
        print(f"  â€¢ é‡å¤è®°å½•: {quality['duplicate_records']} æ¡\n")
        
        # éªŒè¯ç»“æœ
        print("âœ… éªŒè¯ç»“æœ:")
        pass_fail_1 = "âœ“ PASS" if stats['total_symbols'] >= 5000 else "âš  FAIL"
        pass_fail_2 = "âœ“ PASS" if stats['total_records'] >= 50000 else "âš  FAIL"
        pass_fail_3 = "âœ“ PASS" if stats['data_quality']['close_present_pct'] > 99 else "âš  FAIL"
        print(f"  â€¢ è‚¡ç¥¨è¦†ç›– (5000+): {stats['total_symbols']:,} {pass_fail_1}")
        print(f"  â€¢ æ•°æ®é‡ (50000+): {stats['total_records']:,} {pass_fail_2}")
        print(f"  â€¢ æ•°æ®è´¨é‡ (>99%): {stats['data_quality']['close_present_pct']:.1f}% {pass_fail_3}")
        print("\n" + "="*60 + "\n")


def main():
    parser = argparse.ArgumentParser(description="5000+ Aè‚¡é‡‡é›†éªŒè¯å·¥å…·")
    parser.add_argument("--db", default="logs/quotes.db", help="æ•°æ®åº“æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--mode", choices=["hot", "full", "check"], default="check", 
                       help="éªŒè¯æ¨¡å¼")
    parser.add_argument("--check-quality", action="store_true", help="æ‰§è¡Œè¯¦ç»†çš„æ•°æ®è´¨é‡æ£€æŸ¥")
    parser.add_argument("--generate-report", action="store_true", help="ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š")
    parser.add_argument("--output", help="è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰")
    parser.add_argument("--format", choices=["html", "markdown"], default="markdown",
                       help="æŠ¥å‘Šæ ¼å¼")
    
    args = parser.parse_args()
    
    try:
        with CollectionVerifier(args.db) as verifier:
            if args.generate_report:
                if args.format == "html":
                    output_file = args.output or "collection_report.html"
                    verifier.generate_html_report(output_file)
                else:
                    output_file = args.output or "collection_report.md"
                    verifier.generate_markdown_report(output_file)
            else:
                verifier.print_summary()
                
                if args.check_quality:
                    print("\nğŸ” è¯¦ç»†è´¨é‡æ£€æŸ¥:")
                    quality = verifier.check_data_quality()
                    for key, value in quality.items():
                        if isinstance(value, list):
                            print(f"  {key}: {len(value)} é¡¹")
                        else:
                            print(f"  {key}: {value}")
    
    except FileNotFoundError:
        print(f"âŒ é”™è¯¯ï¼šæ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {args.db}")
        exit(1)
    except Exception as e:
        print(f"âŒ é”™è¯¯: {str(e)}")
        exit(1)


if __name__ == "__main__":
    main()
