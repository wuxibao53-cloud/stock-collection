name: Aè‚¡ç¼ è®ºä¿¡å·äº‘ç«¯åˆ†æ

on:
  # å®šæ—¶è¿è¡Œï¼šå·¥ä½œæ—¥ä¸¤æ¬¡ï¼ˆUTCæ¢ç®—ä¸ºä¸­å›½æ—¶åŒº +8ï¼‰
  schedule:
    # å¼€ç›˜å‰ 09:15 CST â†’ 01:15 UTC (UTC+8ï¼Œæ‰€ä»¥9:15-8=1:15)
    # ä½†è¿™æ˜¯UTCï¼ŒåŒ—äº¬æ—¶é—´åº”è¯¥æ˜¯ 09:15ï¼Œæ‰€ä»¥UTCæ˜¯ 09:15-8=01:15 UTC
    # å®é™…ä¸Šï¼šåŒ—äº¬æ—¶é—´09:15 = UTC 01:15ï¼ˆå†¬ä»¤æ—¶ï¼‰æˆ– UTC 00:15ï¼ˆå¤ä»¤æ—¶ï¼‰
    # GitHub ActionsåŸºäºUTCï¼Œæ‰€ä»¥åº”è¯¥ç”¨ 01:15 UTC (å†¬ä»¤æ—¶) æˆ– 00:15 UTC (å¤ä»¤æ—¶)
    # ç»Ÿä¸€ç”¨ 01:15 UTC ç¡®ä¿åœ¨09:15å·¦å³è§¦å‘
    - cron: '15 1 * * 1-5'
    # é—­ç›˜å 15:10 CST â†’ 07:10 UTC
    - cron: '10 7 * * 1-5'
  
  # æ‰‹åŠ¨è§¦å‘
  workflow_dispatch:
    inputs:
      mode:
        description: 'åˆ†ææ¨¡å¼'
        required: false
        default: 'all'
        type: choice
        options:
          - all
          - hot
      history_days:
        description: 'å†å²æ•°æ®å¤©æ•°'
        required: false
        default: '3'
        type: string
      workers:
        description: 'å¹¶å‘çº¿ç¨‹æ•°ï¼ˆæ¨è20ï¼‰'
        required: false
        default: '20'
        type: string
      timeframes:
        description: 'æ—¶é—´æ¡†æ¶ï¼ˆç©ºæ ¼åˆ†éš”ï¼Œå¦‚ï¼š1 5 30ï¼‰'
        required: false
        default: '30'
        type: string

jobs:
  analyze:
    runs-on: ubuntu-latest
    timeout-minutes: 120
    concurrency:
      group: cloud-analysis-${{ github.ref }}
      cancel-in-progress: true
    
    env:
      HTTP_PROXY: ${{ secrets.HTTP_PROXY }}
      HTTPS_PROXY: ${{ secrets.HTTPS_PROXY }}
    
    steps:
      - name: æ£€å‡ºä»£ç 
        uses: actions/checkout@v4
      
      - name: è®¾ç½®Pythonç¯å¢ƒ
        uses: actions/setup-python@v5
        with:
          python-version: '3.13'
          cache: 'pip'
      
      - name: å®‰è£…ä¾èµ–
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt
          # æ˜ç¡®å®‰è£…äº‘ç«¯æ‰€éœ€ä¾èµ–ï¼Œé˜²æ­¢requirementsç¼ºæ¼
          pip install akshare pandas schedule || true
      
      - name: åˆ›å»ºæ—¥å¿—ç›®å½•
        run: mkdir -p logs
      
      # æ•°æ®åº“åˆå§‹åŒ–ç”±multi_timeframe_fetcher.pyçš„__init__è‡ªåŠ¨å®Œæˆ
      
      - name: è·å–30få†å²Kçº¿ï¼ˆå…¨é‡Aè‚¡ï¼ŒåŸºçº¿ï¼‰
        run: |
          MODE="${{ github.event.inputs.mode || 'all' }}"
          DAYS="${{ github.event.inputs.history_days || '30' }}"
          WORKERS="${{ github.event.inputs.workers || '20' }}"  # æ”¯æŒ20çº¿ç¨‹ï¼ˆæ‰‹åŠ¨è§¦å‘å¯è¦†ç›–ï¼Œé»˜è®¤20ï¼‰
          echo "ğŸ“Š åŸºçº¿ï¼šè·å–æœ€è¿‘ ${DAYS} å¤© 30f å†å²Kçº¿ï¼ˆæ¨¡å¼: ${MODE}ï¼Œ${WORKERS}çº¿ç¨‹ï¼‰..."
          python3 multi_timeframe_fetcher.py --db logs/quotes.db --days ${DAYS} --mode ${MODE} --timeframes 30 --workers ${WORKERS} 2>&1 | tee logs/history_fetch_30f.log
          
          # æ•°æ®é‡‡é›†åè¯Šæ–­
          echo ""
          echo "ğŸ“Š æ•°æ®åº“è¯Šæ–­ï¼š"
          python3 << 'DIAG'
          import sqlite3
          db = 'logs/quotes.db'
          conn = sqlite3.connect(db)
          cur = conn.cursor()
          
          # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
          cur.execute("SELECT name FROM sqlite_master WHERE type='table' AND name LIKE 'minute_bars_%'")
          tables = cur.fetchall()
          print(f"âœ“ æ•°æ®è¡¨æ•°é‡: {len(tables)}")
          
          # æ£€æŸ¥30fæ•°æ®
          cur.execute("SELECT COUNT(DISTINCT symbol) FROM minute_bars_30f")
          symbol_count = cur.fetchone()[0]
          print(f"âœ“ 30fè‚¡ç¥¨æ•°: {symbol_count}")
          
          cur.execute("SELECT COUNT(*) FROM minute_bars_30f")
          bar_count = cur.fetchone()[0]
          print(f"âœ“ 30f Kçº¿æ•°: {bar_count}")
          
          conn.close()
          DIAG

      - name: ç”Ÿæˆå€™é€‰è‚¡ç¥¨åˆ—è¡¨ï¼ˆåŸºäº30fåˆ†å‹ï¼‰
        run: |
          python3 << 'EOF'
          import sqlite3
          from multi_timeframe_fetcher import MultiTimeframeDataFetcher, TimeFrame
          
          db='logs/quotes.db'
          
          # å…ˆæ£€æŸ¥æ•°æ®åº“çŠ¶æ€
          conn = sqlite3.connect(db)
          cur = conn.cursor()
          cur.execute('SELECT COUNT(*) FROM minute_bars_30f')
          total_bars = cur.fetchone()[0]
          cur.execute('SELECT COUNT(DISTINCT symbol) FROM minute_bars_30f')
          total_symbols = cur.fetchone()[0]
          conn.close()
          
          print(f"ğŸ“Š 30fæ•°æ®åº“çŠ¶æ€: {total_symbols} åªè‚¡ç¥¨, {total_bars} æ¡Kçº¿")
          
          if total_symbols == 0:
            print("âŒ æ²¡æœ‰æ•°æ®ï¼æ— æ³•ç”Ÿæˆå€™é€‰")
            with open('logs/watchlist.txt','w') as w:
              pass
            print("âœ“ å€™é€‰è‚¡ç¥¨æ•°: 0 (å·²å†™å…¥ logs/watchlist.txt)")
            exit(0)
          
          # åˆå§‹åŒ–åˆ†æå™¨
          f = MultiTimeframeDataFetcher(db)
          
          # è¯»å–æ‰€æœ‰è‚¡ç¥¨ç¬¦å·
          conn = sqlite3.connect(db)
          cur = conn.cursor()
          cur.execute('SELECT DISTINCT symbol FROM minute_bars_30f ORDER BY symbol')
          symbols = [row[0] for row in cur.fetchall()]
          conn.close()
          
          print(f"ğŸ“Š æ‰«æ {len(symbols)} åªè‚¡ç¥¨çš„30fåˆ†å‹...")
          
          watch = []
          for i,s in enumerate(symbols,1):
            fr = f.detect_fractal_patterns(s, TimeFrame.THIRTY_MIN)
            if fr:
              watch.append(s)
            if i % 200 == 0:
              print(f"  è¿›åº¦: {i}/{len(symbols)}, å€™é€‰: {len(watch)} åª")
          
          # ä¿å­˜ç»“æœ
          with open('logs/watchlist.txt','w') as w:
            for s in watch:
              w.write(s+'\n')
          
          print(f"âœ“ å€™é€‰è‚¡ç¥¨æ•°: {len(watch)} (å·²å†™å…¥ logs/watchlist.txt)")
          if len(watch) > 0:
            print(f"  å‰5åª: {', '.join(watch[:5])}")
          EOF

      - name: è·å–å€™é€‰è‚¡ç¥¨çš„1f/5fï¼ˆç²¾ç»†åŒ–ï¼‰
        run: |
          # æ£€æŸ¥å€™é€‰åˆ—è¡¨
          if [ ! -f "logs/watchlist.txt" ] || [ ! -s "logs/watchlist.txt" ]; then
            echo "âš ï¸  æ²¡æœ‰å€™é€‰è‚¡ç¥¨ï¼Œè·³è¿‡1f/5fé‡‡é›†"
            exit 0
          fi
          
          # ç»Ÿè®¡å€™é€‰æ•°é‡
          WATCH_COUNT=$(wc -l < logs/watchlist.txt)
          echo "ğŸ“Š å€™é€‰è‚¡ç¥¨æ•°: $WATCH_COUNT"
          
          # å¦‚æœæ²¡æœ‰å€™é€‰ï¼Œç»“æŸ
          if [ "$WATCH_COUNT" -eq 0 ]; then
            echo "âš ï¸  æ²¡æœ‰å€™é€‰è‚¡ç¥¨ï¼Œè·³è¿‡1f/5fé‡‡é›†"
            exit 0
          fi
          
          echo "ğŸ” å¯¹ $WATCH_COUNT åªå€™é€‰è‚¡ç¥¨è·å– 1f/5f æ•°æ®..."
          python3 << 'EOF'
          import sqlite3
          from multi_timeframe_fetcher import MultiTimeframeDataFetcher, TimeFrame
          
          db='logs/quotes.db'
          f = MultiTimeframeDataFetcher(db)
          
          # è¯»å–å€™é€‰åˆ—è¡¨
          with open('logs/watchlist.txt') as r:
            syms = [line.strip() for line in r if line.strip()]
          
          print(f"ğŸ“Š å¤„ç† {len(syms)} åªå€™é€‰è‚¡ç¥¨...")
          
          # é‡‡é›†1få’Œ5f
          tfs = [TimeFrame.ONE_MIN, TimeFrame.FIVE_MIN]
          
          success_count = 0
          for i, s in enumerate(syms, 1):
            try:
              bars = f.fetch_stock_multiframe_akshare(s, days=3, timeframes=tfs)
              if any(bars.values()):
                f.save_multiframe_bars(s, bars)
                success_count += 1
            except Exception as e:
              pass
            
            if i % 20 == 0:
              print(f"  è¿›åº¦: {i}/{len(syms)}, æˆåŠŸ: {success_count}")
          
          print(f"âœ“ å€™é€‰è‚¡ç¥¨1f/5fæ›´æ–°å®Œæˆ (æˆåŠŸ: {success_count}/{len(syms)})")
          EOF
      
      - name: å®æ—¶é‡‡é›†å½“å‰è¡Œæƒ…
        run: |
          MODE="${{ github.event.inputs.mode || 'all' }}"
          echo "ğŸ”„ é‡‡é›†å®æ—¶è¡Œæƒ…ï¼ˆæ¨¡å¼: ${MODE}ï¼‰..."
          python3 full_a_stock_collector.py --db logs/quotes.db --mode ${MODE} --async 2>&1 | tee logs/realtime_collect.log || true
      
      - name: éªŒè¯æ•°æ®é‡ï¼ˆå¤šæ—¶é—´æ¡†æ¶ï¼‰
        run: |
          python3 << 'EOF'
          import sqlite3
          conn = sqlite3.connect('logs/quotes.db')
          c = conn.cursor()

          def count_table(name):
            try:
              return c.execute(f'SELECT COUNT(*) FROM {name}').fetchone()[0]
            except Exception:
              return 0

          total_1f = count_table('minute_bars_1f')
          total_5f = count_table('minute_bars_5f')
          total_30f = count_table('minute_bars_30f')

          print('\nğŸ“Š å¤šæ—¶é—´æ¡†æ¶æ•°æ®ç»Ÿè®¡')
          print('=' * 60)
          print(f'1f æ€»Kçº¿æ•°: {total_1f}')
          print(f'5f æ€»Kçº¿æ•°: {total_5f}')
          print(f'30f æ€»Kçº¿æ•°: {total_30f}')

          # 30f æ¯åªè‚¡ç¥¨Kçº¿æ•° Top10
          try:
            c.execute('''
            SELECT symbol, COUNT(*) as cnt 
            FROM minute_bars_30f 
            GROUP BY symbol 
            ORDER BY cnt DESC 
            LIMIT 10
            ''')
            print('\nTop 10 (30f æ•°æ®é‡):')
            for symbol, cnt in c.fetchall():
              print(f'  {symbol:12} {cnt:6} æ¡')
          except Exception:
            pass

          conn.close()
          
          if (total_1f + total_5f + total_30f) < 50:
            print('\nâš ï¸  è­¦å‘Š: æ•°æ®é‡ä¸è¶³ï¼Œä¿¡å·å¯èƒ½ä¸ºç©º')
          EOF
      
      - name: ç¼ è®ºä¿¡å·åˆ†æ
        run: |
          echo "ğŸ” å¼€å§‹ç¼ è®ºä¸‰ç±»ä¹°å–ç‚¹åˆ†æ..."
          python3 << 'EOF' 2>&1 | tee logs/analysis.log
          from chan_integrated_system import ChanTradingSystemIntegrated
          import logging
          
          logging.basicConfig(level=logging.INFO)
          logger = logging.getLogger(__name__)
          
          system = ChanTradingSystemIntegrated('logs/quotes.db')
          symbols = system.get_all_symbols_from_db()
          
          if symbols:
              logger.info(f'åˆ†æ {len(symbols)} åªè‚¡ç¥¨...')
              results = system.analyze_multiple_symbols(symbols)
              report = system.generate_report(results)
              
              with open('logs/signals_report.txt', 'w', encoding='utf-8') as f:
                  f.write(report)
              
              print(report)
          else:
              logger.warning('æ— æ•°æ®å¯åˆ†æ')
          EOF
      
      - name: å›æµ‹éªŒè¯ï¼ˆå¯é€‰ï¼‰
        continue-on-error: true
        run: |
          echo "ğŸ“ˆ è¿è¡Œå›æµ‹..."
          python3 run_complete_system.py --mode backtest 2>&1 | tee logs/backtest.log || true
      
      - name: ç”Ÿæˆæ‘˜è¦æŠ¥å‘Š
        if: always()
        run: |
          python3 << 'EOF'
          import sqlite3
          from datetime import datetime
          
          try:
              conn = sqlite3.connect("logs/quotes.db")
              cursor = conn.cursor()
              
              total = cursor.execute("SELECT COUNT(*) FROM minute_bars").fetchone()[0]
              symbols = cursor.execute("SELECT COUNT(DISTINCT symbol) FROM minute_bars").fetchone()[0]
              
              print("=" * 70)
              print("ç¼ è®ºäº¤æ˜“ç³»ç»Ÿäº‘ç«¯åˆ†ææŠ¥å‘Š")
              print("=" * 70)
              print()
              print("ğŸ“… è¿è¡Œæ—¶é—´:", datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
              print()
              print("ğŸ“Š æ•°æ®ç»Ÿè®¡:")
              print(f"  - è‚¡ç¥¨æ•°é‡: {symbols}")
              print(f"  - Kçº¿æ€»æ•°: {total}")
              print(f"  - å¹³å‡æ·±åº¦: {total // max(symbols, 1)} æ¡/è‚¡")
              print()
              print("ğŸ“ è¾“å‡ºæ–‡ä»¶:")
              print("  - logs/history_fetch.log   (å†å²æ•°æ®è·å–)")
              print("  - logs/realtime_collect.log (å®æ—¶é‡‡é›†)")
              print("  - logs/analysis.log        (ä¿¡å·åˆ†æ)")
              print("  - logs/signals_report.txt  (ä¿¡å·æŠ¥å‘Š)")
              print("  - logs/backtest.log        (å›æµ‹ç»“æœ)")
              print()
              print("=" * 70)
              
              conn.close()
          except Exception as e:
              print(f"æ•°æ®ç»Ÿè®¡å¤±è´¥: {e}")
          EOF
      
      - name: ä¸Šä¼ åˆ†æäº§ç‰©
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: analysis-reports-${{ github.run_number }}
          path: |
            logs/*.log
            logs/*.txt
            logs/quotes.db
          retention-days: 30
