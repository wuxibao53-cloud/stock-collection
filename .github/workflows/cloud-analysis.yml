name: Aè‚¡ç¼ è®ºä¿¡å·äº‘ç«¯åˆ†æ

on:
  # å®šæ—¶è¿è¡Œï¼šå·¥ä½œæ—¥æ¯å°æ—¶è¿è¡Œä¸€æ¬¡
  schedule:
    - cron: '0 * * * 1-5'  # å‘¨ä¸€åˆ°å‘¨äº”ï¼Œæ¯å°æ—¶
  
  # æ‰‹åŠ¨è§¦å‘
  workflow_dispatch:
    inputs:
      fetch_history:
        description: 'æ˜¯å¦è·å–å†å²æ•°æ®'
        required: false
        default: 'true'
        type: choice
        options:
          - 'true'
          - 'false'
      history_days:
        description: 'å†å²æ•°æ®å¤©æ•°'
        required: false
        default: '5'
        type: string

jobs:
  analyze:
    runs-on: ubuntu-latest
    timeout-minutes: 45
    
    env:
      HTTP_PROXY: ${{ secrets.HTTP_PROXY }}
      HTTPS_PROXY: ${{ secrets.HTTPS_PROXY }}
    
    steps:
      - name: æ£€å‡ºä»£ç 
        uses: actions/checkout@v4
      
      - name: è®¾ç½®Pythonç¯å¢ƒ
        uses: actions/setup-python@v5
        with:
          python-version: '3.13'
          cache: 'pip'
      
      - name: å®‰è£…ä¾èµ–
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: åˆ›å»ºæ—¥å¿—ç›®å½•
        run: mkdir -p logs
      
      - name: åˆå§‹åŒ–æ•°æ®åº“
        run: |
          python3 -c "
          import sqlite3
          conn = sqlite3.connect('logs/quotes.db')
          cursor = conn.cursor()
          cursor.execute('PRAGMA journal_mode=WAL')
          cursor.execute('''
            CREATE TABLE IF NOT EXISTS minute_bars (
              id INTEGER PRIMARY KEY,
              symbol TEXT NOT NULL,
              minute TEXT NOT NULL,
              open REAL, high REAL, low REAL, close REAL,
              volume INTEGER, amount REAL,
              UNIQUE(symbol, minute)
            )
          ''')
          cursor.execute('CREATE INDEX IF NOT EXISTS idx_symbol_minute ON minute_bars(symbol, minute DESC)')
          conn.commit()
          conn.close()
          print('âœ“ æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ')
          "
      
      - name: è·å–å†å²Kçº¿æ•°æ®ï¼ˆAKShareï¼‰
        if: github.event.inputs.fetch_history != 'false'
        run: |
          DAYS="${{ github.event.inputs.history_days || '5' }}"
          echo "ğŸ“Š è·å–æœ€è¿‘ ${DAYS} å¤©å†å²åˆ†é’ŸKçº¿..."
          python3 historical_data_fetcher.py --db logs/quotes.db --days ${DAYS} 2>&1 | tee logs/history_fetch.log
      
      - name: å®æ—¶é‡‡é›†å½“å‰è¡Œæƒ…
        run: |
          echo "ğŸ”„ é‡‡é›†å®æ—¶è¡Œæƒ…..."
          python3 full_a_stock_collector.py --db logs/quotes.db --mode hot --async 2>&1 | tee logs/realtime_collect.log || true
      
      - name: éªŒè¯æ•°æ®é‡
        run: |
          python3 -c "
          import sqlite3
          conn = sqlite3.connect('logs/quotes.db')
          cursor = conn.cursor()
          
          # æ€»æ•°æ®é‡
          total = cursor.execute('SELECT COUNT(*) FROM minute_bars').fetchone()[0]
          
          # æ¯åªè‚¡ç¥¨Kçº¿æ•°
          cursor.execute('''
            SELECT symbol, COUNT(*) as cnt 
            FROM minute_bars 
            GROUP BY symbol 
            ORDER BY cnt DESC 
            LIMIT 10
          ''')
          
          print(f'\nğŸ“Š æ•°æ®ç»Ÿè®¡')
          print(f'{'='*60}')
          print(f'æ€»Kçº¿æ•°: {total}')
          print(f'\nTop 10 æ•°æ®é‡:')
          for symbol, cnt in cursor.fetchall():
              print(f'  {symbol:12} {cnt:6} æ¡')
          
          conn.close()
          
          if total < 50:
              print('\nâš ï¸  è­¦å‘Š: æ•°æ®é‡ä¸è¶³ï¼Œä¿¡å·å¯èƒ½ä¸ºç©º')
          "
      
      - name: ç¼ è®ºä¿¡å·åˆ†æ
        run: |
          echo "ğŸ” å¼€å§‹ç¼ è®ºä¸‰ç±»ä¹°å–ç‚¹åˆ†æ..."
          python3 -c "
          from chan_integrated_system import ChanTradingSystemIntegrated
          import logging
          
          logging.basicConfig(level=logging.INFO)
          logger = logging.getLogger(__name__)
          
          system = ChanTradingSystemIntegrated('logs/quotes.db')
          symbols = system.get_all_symbols_from_db()
          
          if symbols:
              logger.info(f'åˆ†æ {len(symbols)} åªè‚¡ç¥¨...')
              results = system.analyze_multiple_symbols(symbols)
              report = system.generate_report(results)
              
              with open('logs/signals_report.txt', 'w', encoding='utf-8') as f:
                  f.write(report)
              
              print(report)
          else:
              logger.warning('æ— æ•°æ®å¯åˆ†æ')
          " 2>&1 | tee logs/analysis.log
      
      - name: å›æµ‹éªŒè¯ï¼ˆå¯é€‰ï¼‰
        continue-on-error: true
        run: |
          echo "ğŸ“ˆ è¿è¡Œå›æµ‹..."
          python3 run_complete_system.py --mode backtest 2>&1 | tee logs/backtest.log || true
      
      - name: ç”Ÿæˆæ‘˜è¦æŠ¥å‘Š
        if: always()
        run: |
          python3 -c "
          import sqlite3
          from datetime import datetime
          
          conn = sqlite3.connect('logs/quotes.db')
          cursor = conn.cursor()
          
          total = cursor.execute('SELECT COUNT(*) FROM minute_bars').fetchone()[0]
          symbols = cursor.execute('SELECT COUNT(DISTINCT symbol) FROM minute_bars').fetchone()[0]
          
          print(f'''
{'='*70}
ç¼ è®ºäº¤æ˜“ç³»ç»Ÿäº‘ç«¯åˆ†ææŠ¥å‘Š
{'='*70}

ğŸ“… è¿è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

ğŸ“Š æ•°æ®ç»Ÿè®¡:
  - è‚¡ç¥¨æ•°é‡: {symbols}
  - Kçº¿æ€»æ•°: {total}
  - å¹³å‡æ·±åº¦: {total // max(symbols, 1)} æ¡/è‚¡

ğŸ“ è¾“å‡ºæ–‡ä»¶:
  - logs/history_fetch.log   (å†å²æ•°æ®è·å–)
  - logs/realtime_collect.log (å®æ—¶é‡‡é›†)
  - logs/analysis.log        (ä¿¡å·åˆ†æ)
  - logs/signals_report.txt  (ä¿¡å·æŠ¥å‘Š)
  - logs/backtest.log        (å›æµ‹ç»“æœ)

{'='*70}
          ''')
          
          conn.close()
          "
      
      - name: ä¸Šä¼ åˆ†æäº§ç‰©
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: analysis-reports-${{ github.run_number }}
          path: |
            logs/*.log
            logs/*.txt
            logs/quotes.db
          retention-days: 30
