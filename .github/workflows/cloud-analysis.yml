name: Aè‚¡ç¼ è®ºä¿¡å·äº‘ç«¯åˆ†æ

on:
  # å®šæ—¶è¿è¡Œï¼šå·¥ä½œæ—¥ä¸¤æ¬¡ï¼ˆUTCæ¢ç®—ä¸ºä¸­å›½æ—¶åŒº +8ï¼‰
  schedule:
    # å¼€ç›˜å‰ 09:15 CST â†’ 01:15 UTC
    - cron: '15 1 * * 1-5'
    # é—­ç›˜å 15:10 CST â†’ 07:10 UTC
    - cron: '10 7 * * 1-5'
  
  # æ‰‹åŠ¨è§¦å‘
  workflow_dispatch:
    inputs:
      mode:
        description: 'åˆ†ææ¨¡å¼'
        required: false
        default: 'all'
        type: choice
        options:
          - all
          - hot
      history_days:
        description: 'å†å²æ•°æ®å¤©æ•°'
        required: false
        default: '3'
        type: string
      timeframes:
        description: 'æ—¶é—´æ¡†æ¶ï¼ˆç©ºæ ¼åˆ†éš”ï¼Œå¦‚ï¼š1 5 30ï¼‰'
        required: false
        default: '30'
        type: string

jobs:
  analyze:
    runs-on: ubuntu-latest
    timeout-minutes: 120
    concurrency:
      group: cloud-analysis-${{ github.ref }}
      cancel-in-progress: true
    
    env:
      HTTP_PROXY: ${{ secrets.HTTP_PROXY }}
      HTTPS_PROXY: ${{ secrets.HTTPS_PROXY }}
    
    steps:
      - name: æ£€å‡ºä»£ç 
        uses: actions/checkout@v4
      
      - name: è®¾ç½®Pythonç¯å¢ƒ
        uses: actions/setup-python@v5
        with:
          python-version: '3.13'
          cache: 'pip'
      
      - name: å®‰è£…ä¾èµ–
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt
          # æ˜ç¡®å®‰è£…äº‘ç«¯æ‰€éœ€ä¾èµ–ï¼Œé˜²æ­¢requirementsç¼ºæ¼
          pip install akshare pandas schedule || true
      
      - name: åˆ›å»ºæ—¥å¿—ç›®å½•
        run: mkdir -p logs
      
      - name: åˆå§‹åŒ–æ•°æ®åº“
        run: |
          python3 << 'EOF'
          import sqlite3
          conn = sqlite3.connect('logs/quotes.db')
          cursor = conn.cursor()
          cursor.execute('PRAGMA journal_mode=WAL')
          cursor.execute('''
            CREATE TABLE IF NOT EXISTS minute_bars (
              id INTEGER PRIMARY KEY,
              symbol TEXT NOT NULL,
              minute TEXT NOT NULL,
              open REAL, high REAL, low REAL, close REAL,
              volume INTEGER, amount REAL,
              UNIQUE(symbol, minute)
            )
          ''')
          cursor.execute('CREATE INDEX IF NOT EXISTS idx_symbol_minute ON minute_bars(symbol, minute DESC)')
          conn.commit()
          conn.close()
          print('âœ“ æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ')
          EOF
      
        - name: è·å–30få†å²Kçº¿ï¼ˆå…¨é‡Aè‚¡ï¼ŒåŸºçº¿ï¼‰
        run: |
          MODE="${{ github.event.inputs.mode || 'all' }}"
          DAYS="${{ github.event.inputs.history_days || '3' }}"
          # å®šæ—¶ä»»åŠ¡é»˜è®¤ä»…æ‹‰å–30fï¼Œæ‰‹åŠ¨å¯è¦†ç›–ä¸ºæ›´å¤šæ—¶é—´æ¡†æ¶ï¼ˆè§ä¸‹ä¸€æ­¥ï¼‰
          echo "ğŸ“Š åŸºçº¿ï¼šè·å–æœ€è¿‘ ${DAYS} å¤© 30f å†å²Kçº¿ï¼ˆæ¨¡å¼: ${MODE}ï¼‰..."
          python3 multi_timeframe_fetcher.py --db logs/quotes.db --days ${DAYS} --mode ${MODE} --timeframes 30 2>&1 | tee logs/history_fetch_30f.log

        - name: ç”Ÿæˆå€™é€‰è‚¡ç¥¨åˆ—è¡¨ï¼ˆåŸºäº30fåˆ†å‹ï¼‰
        run: |
          python3 << 'EOF'
          import sqlite3
          from multi_timeframe_fetcher import MultiTimeframeDataFetcher, TimeFrame
          
          db='logs/quotes.db'
          f = MultiTimeframeDataFetcher(db)
          conn = sqlite3.connect(db)
          cur = conn.cursor()
          cur.execute('SELECT DISTINCT symbol FROM minute_bars_30f')
          symbols = [row[0] for row in cur.fetchall()]
          conn.close()
          
          watch = []
          for i,s in enumerate(symbols,1):
            fr = f.detect_fractal_patterns(s, TimeFrame.THIRTY_MIN)
            if fr:
              watch.append(s)
            if i % 200 == 0:
              print(f"æ‰«æè¿›åº¦ {i}/{len(symbols)}ï¼Œå€™é€‰ {len(watch)} åª...")
          
          with open('logs/watchlist.txt','w') as w:
            for s in watch:
              w.write(s+'\n')
          print(f"âœ“ å€™é€‰è‚¡ç¥¨æ•°: {len(watch)} (å·²å†™å…¥ logs/watchlist.txt)")
          EOF

        - name: è·å–å€™é€‰è‚¡ç¥¨çš„1f/5fï¼ˆç²¾ç»†åŒ–ï¼‰
        run: |
          # æ‰‹åŠ¨è§¦å‘å¯è¦†ç›–æ—¶é—´æ¡†æ¶ï¼›é»˜è®¤ä»…å¯¹å€™é€‰è‚¡è·å– 1 å’Œ 5
          TF_INPUTS="${{ github.event.inputs.timeframes || '' }}"
          if [ -z "$TF_INPUTS" ]; then TF_INPUTS="1 5"; fi
          echo "ğŸ” å¯¹å€™é€‰è‚¡ç¥¨è·å–æ—¶é—´æ¡†æ¶: $TF_INPUTS"
          python3 << 'EOF'
          import sqlite3
          from multi_timeframe_fetcher import MultiTimeframeDataFetcher, TimeFrame
          
          db='logs/quotes.db'
          f = MultiTimeframeDataFetcher(db)
          # è¯»å–å€™é€‰åˆ—è¡¨
          with open('logs/watchlist.txt') as r:
            syms=[line.strip() for line in r if line.strip()]
          
          # è§£ææ—¶é—´æ¡†æ¶ï¼ˆæ¥è‡ªç¯å¢ƒå˜é‡åœ¨æ­¤ä¸å¯è§ï¼Œç»Ÿä¸€ç”¨ 1/5ï¼‰
          tfs=[TimeFrame.ONE_MIN, TimeFrame.FIVE_MIN]
          
          for i,s in enumerate(syms,1):
            bars=f.fetch_stock_multiframe_akshare(s, days=3, timeframes=tfs)
            if any(bars.values()):
              f.save_multiframe_bars(s, bars)
            if i % 50 == 0:
              print(f"å·²å¤„ç†å€™é€‰ {i}/{len(syms)} ...")
          print("âœ“ å€™é€‰è‚¡ç¥¨1f/5fæ›´æ–°å®Œæˆ")
          EOF
      
      - name: å®æ—¶é‡‡é›†å½“å‰è¡Œæƒ…
        run: |
          MODE="${{ github.event.inputs.mode || 'all' }}"
          echo "ğŸ”„ é‡‡é›†å®æ—¶è¡Œæƒ…ï¼ˆæ¨¡å¼: ${MODE}ï¼‰..."
          python3 full_a_stock_collector.py --db logs/quotes.db --mode ${MODE} --async 2>&1 | tee logs/realtime_collect.log || true
      
        - name: éªŒè¯æ•°æ®é‡ï¼ˆå¤šæ—¶é—´æ¡†æ¶ï¼‰
        run: |
          python3 << 'EOF'
          import sqlite3
          conn = sqlite3.connect('logs/quotes.db')
          c = conn.cursor()

          def count_table(name):
            try:
              return c.execute(f'SELECT COUNT(*) FROM {name}').fetchone()[0]
            except Exception:
              return 0

          total_1f = count_table('minute_bars_1f')
          total_5f = count_table('minute_bars_5f')
          total_30f = count_table('minute_bars_30f')

          print('\nğŸ“Š å¤šæ—¶é—´æ¡†æ¶æ•°æ®ç»Ÿè®¡')
          print('=' * 60)
          print(f'1f æ€»Kçº¿æ•°: {total_1f}')
          print(f'5f æ€»Kçº¿æ•°: {total_5f}')
          print(f'30f æ€»Kçº¿æ•°: {total_30f}')

          # 30f æ¯åªè‚¡ç¥¨Kçº¿æ•° Top10
          try:
            c.execute('''
            SELECT symbol, COUNT(*) as cnt 
            FROM minute_bars_30f 
            GROUP BY symbol 
            ORDER BY cnt DESC 
            LIMIT 10
            ''')
            print('\nTop 10 (30f æ•°æ®é‡):')
            for symbol, cnt in c.fetchall():
              print(f'  {symbol:12} {cnt:6} æ¡')
          except Exception:
            pass

          conn.close()
            if (total_1f + total_5f + total_30f) < 50:
            print('\nâš ï¸  è­¦å‘Š: æ•°æ®é‡ä¸è¶³ï¼Œä¿¡å·å¯èƒ½ä¸ºç©º')
          EOF
      
      - name: ç¼ è®ºä¿¡å·åˆ†æ
        run: |
          echo "ğŸ” å¼€å§‹ç¼ è®ºä¸‰ç±»ä¹°å–ç‚¹åˆ†æ..."
          python3 << 'EOF' 2>&1 | tee logs/analysis.log
          from chan_integrated_system import ChanTradingSystemIntegrated
          import logging
          
          logging.basicConfig(level=logging.INFO)
          logger = logging.getLogger(__name__)
          
          system = ChanTradingSystemIntegrated('logs/quotes.db')
          symbols = system.get_all_symbols_from_db()
          
          if symbols:
              logger.info(f'åˆ†æ {len(symbols)} åªè‚¡ç¥¨...')
              results = system.analyze_multiple_symbols(symbols)
              report = system.generate_report(results)
              
              with open('logs/signals_report.txt', 'w', encoding='utf-8') as f:
                  f.write(report)
              
              print(report)
          else:
              logger.warning('æ— æ•°æ®å¯åˆ†æ')
          EOF
      
      - name: å›æµ‹éªŒè¯ï¼ˆå¯é€‰ï¼‰
        continue-on-error: true
        run: |
          echo "ğŸ“ˆ è¿è¡Œå›æµ‹..."
          python3 run_complete_system.py --mode backtest 2>&1 | tee logs/backtest.log || true
      
      - name: ç”Ÿæˆæ‘˜è¦æŠ¥å‘Š
        if: always()
        run: |
          python3 << 'EOF'
          import sqlite3
          from datetime import datetime
          
          try:
              conn = sqlite3.connect("logs/quotes.db")
              cursor = conn.cursor()
              
              total = cursor.execute("SELECT COUNT(*) FROM minute_bars").fetchone()[0]
              symbols = cursor.execute("SELECT COUNT(DISTINCT symbol) FROM minute_bars").fetchone()[0]
              
              print("=" * 70)
              print("ç¼ è®ºäº¤æ˜“ç³»ç»Ÿäº‘ç«¯åˆ†ææŠ¥å‘Š")
              print("=" * 70)
              print()
              print("ğŸ“… è¿è¡Œæ—¶é—´:", datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
              print()
              print("ğŸ“Š æ•°æ®ç»Ÿè®¡:")
              print(f"  - è‚¡ç¥¨æ•°é‡: {symbols}")
              print(f"  - Kçº¿æ€»æ•°: {total}")
              print(f"  - å¹³å‡æ·±åº¦: {total // max(symbols, 1)} æ¡/è‚¡")
              print()
              print("ğŸ“ è¾“å‡ºæ–‡ä»¶:")
              print("  - logs/history_fetch.log   (å†å²æ•°æ®è·å–)")
              print("  - logs/realtime_collect.log (å®æ—¶é‡‡é›†)")
              print("  - logs/analysis.log        (ä¿¡å·åˆ†æ)")
              print("  - logs/signals_report.txt  (ä¿¡å·æŠ¥å‘Š)")
              print("  - logs/backtest.log        (å›æµ‹ç»“æœ)")
              print()
              print("=" * 70)
              
              conn.close()
          except Exception as e:
              print(f"æ•°æ®ç»Ÿè®¡å¤±è´¥: {e}")
          EOF
      
      - name: ä¸Šä¼ åˆ†æäº§ç‰©
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: analysis-reports-${{ github.run_number }}
          path: |
            logs/*.log
            logs/*.txt
            logs/quotes.db
          retention-days: 30
