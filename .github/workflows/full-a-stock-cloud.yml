name: 缠论交易系统 - 云端自动执行

on:
  schedule:
    - cron: '0 0 * * 1-5'   # 北京时间 08:00 预热
    - cron: '35 1 * * 1-5'  # 北京时间 09:35 开盘后5分钟
    - cron: '35 3 * * 1-5'  # 北京时间 11:35 午盘前5分钟
    - cron: '5 7 * * 1-5'   # 北京时间 15:05 收盘后5分钟
  workflow_dispatch:
    inputs:
      mode:
        description: '执行模式'
        required: true
        type: choice
        default: alert
        options:
          - incremental
          - full
          - analysis
          - alert

jobs:
  market-collection:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    steps:
      - name: 检出代码
        uses: actions/checkout@v4

      - name: 打印环境信息
        run: |
          uname -a
          python3 --version || true
          ls -la

      - name: 设置 Python 环境
        uses: actio  /setup        uses: actio  /setup        uses: ave        uses: actio  /setache: 'pip'

      - name: 安装依赖
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi

      - name: 创建日志目录
        run: mkdir -p logs

      - name: 采集热门股票数据 (增量模式)
        if: ${{ github.event.inputs.mode == 'incremental' || github.event_name == 'schedule' }}
        run: python full_a_stock_collector.py --db logs/quotes.db --mode hot

      - name: 采集全A股数据 (完整模式)
        if: ${{ github.event.inputs.mode == 'full' }}
        run: python full_a_stock_collector.py --db logs/quotes.db --mode all

      - name: 运行缠论分析
        if: ${{ github.event.inputs.mode == 'analysis' }}
        run: python chan_trading_system.py --db logs/quotes.db --export

      - name: 生成监控输出 (alert)
        if: ${{ github.event.inputs.mode == 'alert' }}
        run: python monitor.py --db logs/quotes.db > logs/monitor_output.txt 2>&1 || true

      - name: 检查数据质量
        run: |
          python - <<'PY'
          import sqlite3
          try:
              conn = sqlite3.connect('logs/quotes.db')
              cur = conn.cursor()
              cur.execute('SELECT COUNT(DISTINCT symbol), COUNT(*) FROM minute_bars')
              row = cur.fetchone()
              symbols, records = row if row else (0, 0)
              print(f'✓ 采集{symbols}只股票, {records}条数据')
          except Exception as e:
              print(f'⚠️ 数据库检查失败: {e}')
          finally:
              try:
                  conn.close()
              except Exception:
                  pass
          PY

      - name: 上传数据和报告
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: analysis-results
          path: |
            logs/quotes.db
            logs/chan_report.json
            logs/monitor_output.txt
          retention-days: 30

      - name: 采集成功通知
        if: success()
        env:
          DINGTALK_WEBHOOK: ${{ secrets.DINGTALK_WEBHOOK }}
          WECHAT_WEBHOOK: ${{ secrets.WECHAT_WEBHOOK }}
          GITHUB_RUN_ID: ${{ github.run_id }}
          GITHUB_REPOSITORY: ${{ github.repository }}
          GITHUB_SERVER_URL: ${{ github.server_url }}
        run: |
          python notify_alert.py \
            --status success \
            --symbols 100 \
            --records 5000 \
            --runtime 120 \
            --message "云端自动执行成功"

      - name: 采集失败通知
        if: failure()
        env:
          DINGTALK_WEBHOOK: ${{ secrets.DINGTALK_WEBHOOK }}
          WECHAT_WEBHOOK: ${{ secrets.WECHAT_WEBHOOK }}
          GITHUB_RUN_ID: ${{ github.run_id }}
          GITHUB_REPOSITORY: ${{ github.repository }}
          GITHUB_SERVER_URL: ${{ github.server_url }}
        run: |
          python notify_alert.py \
            --status failure \
            --error "采集过程中出现错误，请检查日志"

  data-aggregation:
    needs: market-collection
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: 检出代码
        uses: actions/checkout@v4

      - name: 设置 Python 环境
        uses: actions/setup-python@v5
        with:
          python-version: '3.13'

      - name: 安装依赖
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi

      - name: 下载采集结果
        uses: actions/download-artifact@v4
        with:
          name: analysis-results
          path: logs/

      - name: 数据聚合和去重
        run: |
          python - <<'PY'
          import sqlite3
          conn = sqlite3.connect('logs/quotes.db')
          cur = conn.cursor()
          cur.execute('DELETE FROM minute_bars WHERE rowid NOT IN (SELECT MIN(rowid) FROM minute_bars GROUP BY symbol, minute)')
          conn.commit()
          conn.close()
          print('✓ 数据去重完成')
          PY

      - name: 上传最终数据
        uses: actions/upload-artifact@v4
        with:
          name: final-database
          path: logs/quotes.db
          retention-days: 90

  monitoring-alerts:
    needs: data-aggregation
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: 检出代码
        uses: actions/checkout@v4

      - name: 设置 Python 环境
        uses: actions/setup-python@v5
        with:
          python-version: '3.13'

      - name: 下载最终数据
        uses: actions/download-artifact@v4
        with:
          name: final-database
          path: logs/

      - name: 生成监控报告
        run: |
          python - <<'PY'
          import json, sqlite3
          from datetime import datetime
          conn = sqlite3.connect('logs/quotes.db')
          cur = conn.cursor()
          cur.execute('SELECT COUNT(DISTINCT symbol), COUNT(*) FROM minute_bars')
          row = cur.fetchone() or (0, 0)
          symbols, records = row
          report = {
            'timestamp': datetime.now().isoformat(),
            'symbols_collected': symbols,
            'total_records': records,
            'average_records_per_symbol': (records // max(symbols, 1)) if symbols else 0,
            'status': 'SUCCESS'
          }
          import os
          os.makedirs('logs', exist_ok=True)
          with open('logs/monitoring_report.json','w') as f:
              json.dump(report, f, indent=2, ensure_ascii=False)
          print(json.dumps(report, indent=2, ensure_ascii=False))
          conn.close()
          PY

      - name: 保存监控报告
        uses: actions/upload-artifact@v4
        with:
          name: monitoring-report
          path: logs/monitoring_report.json
          retention-days: 90

  cleanup:
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule'
    steps:
      - name: 清理30天前的数据
        run: echo "清理旧数据任务（可选）"
