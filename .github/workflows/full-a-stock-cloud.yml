name: chan-trading-cloud

on:
  schedule:
    - cron: '0 0 * * 1-5'
    - cron: '35 1 * * 1-5'
    - cron: '35 3 * * 1-5'
    - cron: '5 7 * * 1-5'
  workflow_dispatch:
    inputs:
      mode:
        description: Run mode
        required: true
        type: choice
        default: alert
        options:
          - incremental
          - full
          - analysis
          - alert

jobs:
  collect:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    steps:
      - uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.13'
          cache: pip

      - name: Install dependencies
        run: pip install -r requirements.txt

      - run: mkdir -p logs

      - name: Initialize database
        run: |
          python3 << 'EOF'
          import sqlite3
          conn = sqlite3.connect('logs/quotes.db')
          cur = conn.cursor()
          cur.execute('''CREATE TABLE IF NOT EXISTS minute_bars (
            id INTEGER PRIMARY KEY,
            symbol TEXT NOT NULL,
            minute TEXT NOT NULL,
            open REAL, high REAL, low REAL, close REAL,
            volume INTEGER, amount REAL,
            UNIQUE(symbol, minute)
          )''')
          conn.commit()
          conn.close()
          print('✓ Database initialized')
          EOF

      - name: Run collector
        continue-on-error: true
        run: |
          if [ "${{ inputs.mode }}" = "incremental" ]; then
            python full_a_stock_collector.py --db logs/quotes.db --mode hot
          elif [ "${{ inputs.mode }}" = "full" ]; then
            python full_a_stock_collector.py --db logs/quotes.db --mode all
          elif [ "${{ inputs.mode }}" = "analysis" ]; then
            python chan_trading_system.py --db logs/quotes.db --export
          elif [ "${{ inputs.mode }}" = "alert" ]; then
            python monitor.py --db logs/quotes.db
          fi

      - name: Verify data
        run: |
          python3 << 'EOF'
          import sqlite3
          try:
            conn = sqlite3.connect('logs/quotes.db')
            cur = conn.cursor()
            cur.execute('SELECT COUNT(DISTINCT symbol), COUNT(*) FROM minute_bars')
            row = cur.fetchone()
            symbols = row[0] if row else 0
            records = row[1] if row else 0
            print(f'✓ Database status: {symbols} symbols, {records} records')
          except Exception as e:
            print(f'✗ Verification failed: {e}')
          EOF

      - name: Upload results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: analysis-results
          path: logs/
          retention-days: 30

      - name: Notify on success
        if: success()
        env:
          DINGTALK: ${{ secrets.DINGTALK_WEBHOOK }}
        run: python notify_alert.py --status success --symbols 100 --records 5000

      - name: Notify on failure
        if: failure()
        env:
          DINGTALK: ${{ secrets.DINGTALK_WEBHOOK }}
        run: python notify_alert.py --status failure --error "Collection failed"

  aggregate:
    needs: collect
    runs-on: ubuntu-latest
    if: always()
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: '3.13'

      - run: pip install -r requirements.txt

      - uses: actions/download-artifact@v4
        with:
          name: analysis-results
          path: logs/

      - name: Deduplicate records
        continue-on-error: true
        run: |
          python3 << 'EOF'
          import sqlite3
          try:
            conn = sqlite3.connect('logs/quotes.db')
            cur = conn.cursor()
            cur.execute('DELETE FROM minute_bars WHERE rowid NOT IN (SELECT MIN(rowid) FROM minute_bars GROUP BY symbol, minute)')
            conn.commit()
            conn.close()
            print('✓ Deduplication complete')
          except Exception as e:
            print(f'✗ Deduplication error: {e}')
          EOF

      - uses: actions/upload-artifact@v4
        with:
          name: final-database
          path: logs/quotes.db
          retention-days: 90

  monitor:
    needs: aggregate
    runs-on: ubuntu-latest
    if: always()
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: '3.13'

      - uses: actions/download-artifact@v4
        with:
          name: final-database
          path: logs/

      - name: Build report
        continue-on-error: true
        run: |
          python3 << 'EOF'
          import json, sqlite3
          from datetime import datetime
          try:
            conn = sqlite3.connect('logs/quotes.db')
            cur = conn.cursor()
            try:
              cur.execute('SELECT COUNT(DISTINCT symbol), COUNT(*) FROM minute_bars')
              row = cur.fetchone() or (0, 0)
            except:
              row = (0, 0)
            symbols, records = row
            report = {
              'timestamp': datetime.now().isoformat(),
              'symbols': symbols,
              'records': records,
              'status': 'SUCCESS' if records > 0 else 'NO_DATA'
            }
            import os
            os.makedirs('logs', exist_ok=True)
            with open('logs/monitoring_report.json','w') as f:
              json.dump(report, f, indent=2)
            print(f'✓ Report generated: {symbols} symbols, {records} records')
          except Exception as e:
            print(f'✗ Report error: {e}')
          EOF

      - uses: actions/upload-artifact@v4
        with:
          name: monitoring-report
          path: logs/monitoring_report.json
          retention-days: 90
